{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKEbZnme7SBR",
        "outputId": "49b42cf1-1f7b-4e37-f907-d7c3043bbb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.6-py3-none-any.whl (29 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain-openai)\n",
            "  Using cached langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.25.2)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Using cached openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.7.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2,>=0.1.16->langchain-openai)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2,>=0.1.16->langchain-openai)\n",
            "  Using cached langsmith-0.1.5-py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai)\n",
            "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.0.7)\n",
            "Installing collected packages: jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.25 langchain-openai-0.0.6 langsmith-0.1.5 openai-1.12.0 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OseWZ1itbr2",
        "outputId": "1499b2a9-634d-4c1b-e032-5106f750a539"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Using cached langchain-0.1.8-py3-none-any.whl (816 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
            "  Using cached langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.25)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Using cached marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.24->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 langchain-0.1.8 langchain-community-0.0.21 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "\n",
        "chat = ChatOpenAI(temperature=0.0)\n",
        "chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfIMoU7-7UNA",
        "outputId": "ea21abcf-692b-4c27-c93d-978e7ace1b70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ae645b637f0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ae645b80cd0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Conversation Chain"
      ],
      "metadata": {
        "id": "78G9MTQq8R78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory() # Our memory buffer\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory = memory,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "7GtI4r928QIg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"\")\n",
        "  if user_input.lower() == 'quit':\n",
        "    break\n",
        "  print(conversation.predict(input=user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCRF1ufb8jum",
        "outputId": "17daf6f1-dd48-4758-857d-27d3fc06ce35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey do you know what langchain is?\n",
            "I'm sorry, but I do not have information on \"langchain.\"\n",
            "Its a framework for working with LLMs\n",
            "Langchain is a framework specifically designed for working with Large Language Models (LLMs). It provides tools and resources to help developers and researchers efficiently train, fine-tune, and deploy LLMs for various natural language processing tasks. Langchain aims to streamline the process of working with LLMs and make it easier for users to leverage the power of these models in their projects.\n",
            "How is the weather in San Francisco?\n",
            "The weather in San Francisco is currently partly cloudy with a temperature of 65 degrees Fahrenheit. There is a slight breeze coming from the west at 10 miles per hour. Overall, it is a pleasant day in San Francisco.\n",
            "Oh okay, is there a chance of rain?\n",
            "There is a 20% chance of rain in San Francisco later this evening. The forecast predicts light showers, so it's always a good idea to carry an umbrella just in case.\n",
            "Okay I will bring a rain jacket\n",
            "That's a good idea! A rain jacket will definitely come in handy if the showers do come. It's always better to be prepared for any weather changes. Enjoy your day in San Francisco!\n",
            "What is langchain again?\n",
            "Langchain is a framework specifically designed for working with Large Language Models (LLMs). It provides tools and resources to help developers and researchers efficiently train, fine-tune, and deploy LLMs for various natural language processing tasks. Langchain aims to streamline the process of working with LLMs and make it easier for users to leverage the power of these models in their projects.\n",
            "quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "id": "Fc3qt_Qk-z6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cddf3b1-fb39-4a55-9a17-8818666b14e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: what is gradient descent?\n",
            "AI: Gradient descent is an optimization algorithm used in machine learning and deep learning to minimize the loss function by iteratively moving in the direction of the steepest descent of the loss function. It calculates the gradient of the loss function with respect to the model parameters and updates the parameters in the opposite direction of the gradient to minimize the loss. This process is repeated until the algorithm converges to a local minimum of the loss function.\n",
            "Human: hey do you know what langchain is?\n",
            "AI: I'm sorry, but I do not have information on \"langchain.\"\n",
            "Human: Its a framework for working with LLMs\n",
            "AI: Langchain is a framework specifically designed for working with Large Language Models (LLMs). It provides tools and resources to help developers and researchers efficiently train, fine-tune, and deploy LLMs for various natural language processing tasks. Langchain aims to streamline the process of working with LLMs and make it easier for users to leverage the power of these models in their projects.\n",
            "Human: How is the weather in San Francisco?\n",
            "AI: The weather in San Francisco is currently partly cloudy with a temperature of 65 degrees Fahrenheit. There is a slight breeze coming from the west at 10 miles per hour. Overall, it is a pleasant day in San Francisco.\n",
            "Human: Oh okay, is there a chance of rain?\n",
            "AI: There is a 20% chance of rain in San Francisco later this evening. The forecast predicts light showers, so it's always a good idea to carry an umbrella just in case.\n",
            "Human: Okay I will bring a rain jacket\n",
            "AI: That's a good idea! A rain jacket will definitely come in handy if the showers do come. It's always better to be prepared for any weather changes. Enjoy your day in San Francisco!\n",
            "Human: What is langchain again?\n",
            "AI: Langchain is a framework specifically designed for working with Large Language Models (LLMs). It provides tools and resources to help developers and researchers efficiently train, fine-tune, and deploy LLMs for various natural language processing tasks. Langchain aims to streamline the process of working with LLMs and make it easier for users to leverage the power of these models in their projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a Buffer Window So Memory Does Not Get Large"
      ],
      "metadata": {
        "id": "-mSv1A4f-sk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(k=2) # window size of 2\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory = memory,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "y0Lt4Qrp8yhq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"\")\n",
        "  if user_input.lower() == 'quit':\n",
        "    break\n",
        "  print(conversation.predict(input=user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKL2izYl-_PV",
        "outputId": "111f5e6f-68de-4bab-a03f-4dfa2758d464"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hey do you know what langchain is?\n",
            "Hello! Yes, Langchain is a blockchain platform that focuses on language learning and education. It uses blockchain technology to create a decentralized ecosystem where users can access language learning materials, connect with tutors, and earn rewards for their progress. It also offers features like smart contracts for language exchange and a marketplace for language-related services. Is there anything specific you would like to know about Langchain?\n",
            "No its a framework for working with LLMs\n",
            "Ah, I see! Langchain is a framework for working with Language Model Models (LLMs). LLMs are a type of artificial intelligence model that can understand and generate human language. Langchain likely provides tools and resources for developers to work with LLMs in various language-related applications. It's interesting how technology is being used to enhance language learning and communication. If you have any more questions or need further information, feel free to ask!\n",
            "Great, what is the weather like in San Francisco?\n",
            "I'm sorry, but I do not have real-time access to weather information. I recommend checking a reliable weather website or app for the most up-to-date weather forecast for San Francisco. Let me know if there is anything else I can help you with!\n",
            "Oh okay, what are some good weather apps?\n",
            "Some popular weather apps that you can consider using are AccuWeather, The Weather Channel, Weather Underground, and Dark Sky. These apps provide detailed weather forecasts, radar maps, and severe weather alerts to help you stay informed about the weather conditions in your area. You can download these apps from the App Store or Google Play Store on your mobile device. Let me know if you need more recommendations or information about weather apps!\n",
            "Thank you. Do you remember what Langchain is?\n",
            "Yes, Langchain is a blockchain-based platform that focuses on language learning and education. It uses blockchain technology to create a decentralized ecosystem where users can access language learning materials, connect with tutors and other learners, and earn rewards for their participation. Langchain aims to make language learning more accessible, interactive, and engaging for users around the world. Let me know if you would like more information about Langchain or any other topic!\n",
            "quit\n"
          ]
        }
      ]
    }
  ]
}